# WEEK 2 PREVIEW - Media Ingest Handler

## Mission
Build the media processing pipeline that extracts text from images (OCR) and videos (YouTube transcripts). Turn Week 1's database schema into working code.

## Deliverables

### 1. OCR Handler (`internal/media/ocr.go`)
Use Google Cloud Vision API to extract text from images with confidence scores.

**Interface:**
```go
type OCRHandler interface {
    ExtractFromURL(ctx context.Context, imageURL string) (*ExtractResult, error)
    ExtractFromFile(ctx context.Context, filePath string) (*ExtractResult, error)
}

type ExtractResult struct {
    Text              string
    ConfidenceScore   float64  // 0-1
    BoundingBoxes     []Box
    Language          string
}
```

**Implementation Plan:**
1. Use google.golang.org/cloud/vision/apiv1
2. Call DOCUMENT_TEXT_DETECTION for best OCR results
3. Parse response â†’ confidence scores
4. Store in `extracted_text.confidence_score`

**Test:**
```bash
curl -X POST http://localhost:8080/v1/media/ocr \
  -H "Content-Type: application/json" \
  -d '{
    "project_id": "xxx",
    "source_id": "yyy",
    "image_url": "https://..."
  }'

# Response:
{
  "media_item_id": "zzz",
  "text": "Extracted text...",
  "confidence": 0.95,
  "language": "en"
}
```

### 2. YouTube Handler (`internal/media/youtube.go`)
Fetch YouTube transcripts for videos using youtube-transcript-api.

**Interface:**
```go
type YouTubeHandler interface {
    GetTranscript(ctx context.Context, videoID string) (*TranscriptResult, error)
}

type TranscriptResult struct {
    Transcript    string
    Language      string
    IsAutoGenerated bool
    Duration      int // seconds
}
```

**Implementation Plan:**
1. Use github.com/jdelesus/youtube-transcript-api (or similar)
2. Extract video ID from URL
3. Fetch transcript (handle multiple languages)
4. Store with timestamps (`extracted_text.timestamp_seconds`)

**Test:**
```bash
curl -X POST http://localhost:8080/v1/media/youtube \
  -H "Content-Type: application/json" \
  -d '{
    "project_id": "xxx",
    "source_id": "yyy",
    "video_url": "https://youtube.com/watch?v=..."
  }'

# Response:
{
  "media_item_id": "zzz",
  "transcript": "Full transcript...",
  "language": "en",
  "segments": [
    {"timestamp": 0, "text": "..."},
    {"timestamp": 30, "text": "..."}
  ]
}
```

### 3. Media Handler Orchestrator (`internal/media/handler.go`)
Decide which handler to use based on media type.

```go
func ProcessMediaItem(ctx context.Context, mediaItem *MediaItem) error {
    switch mediaItem.Type {
    case "image":
        result, err := ocrHandler.ExtractFromURL(ctx, mediaItem.URL)
        if err != nil {
            return err
        }
        return storeExtractedText(ctx, mediaItem.ID, "ocr", result.Text, result.ConfidenceScore)
    
    case "video":
        result, err := youtubeHandler.GetTranscript(ctx, mediaItem.ExternalID)
        if err != nil {
            return err
        }
        return storeExtractedText(ctx, mediaItem.ID, "youtube_transcript", result.Transcript, 1.0)
    
    default:
        return fmt.Errorf("unknown media type: %s", mediaItem.Type)
    }
}
```

### 4. Worker Integration
Add job handler in `cmd/worker/main.go` to process media items.

**Job Structure:**
```json
{
  "type": "process_media",
  "media_item_id": "uuid",
  "project_id": "uuid"
}
```

**Flow:**
1. Worker polls queue for media jobs
2. Fetches media_item from DB
3. Calls appropriate handler (OCR or YouTube)
4. Updates `media_items.processing_status` to 'completed'
5. Inserts row in `extracted_text`

## Database Changes (Week 1 Already Done âœ…)

Both tables ready:
- `media_items` - stores references
- `extracted_text` - stores results

## Environment Variables Needed

```bash
# Google Vision API
GOOGLE_APPLICATION_CREDENTIALS=/path/to/service-account.json
GOOGLE_VISION_API_KEY=...

# YouTube (if authenticated)
YOUTUBE_API_KEY=...
```

## Success Metrics (Week 2 Friday)

- [ ] OCR extracts text from sample image with >90% confidence
- [ ] YouTube handler fetches transcripts for 3+ videos
- [ ] Worker job processes media_items from queue
- [ ] `extracted_text` table populated with results
- [ ] No data loss (all fields stored correctly)
- [ ] `go build ./...` passes
- [ ] Tests cover >70% of code

## Dependencies to Add

```bash
go get github.com/googleapis/google-cloud-go/vision/apiv1
go get github.com/kkdai/youtube/v2
go get github.com/go-echarts/go-echarts
```

Or find better YouTube library:
- github.com/jdelesus/youtube-transcript-api
- github.com/davidvujic/youtube-go

## Time Budget

- OCR Handler: 4 hours (API integration, error handling)
- YouTube Handler: 2 hours (simpler API)
- Orchestrator: 1 hour
- Worker Job: 2 hours
- Testing: 3 hours
- **Total: ~12 hours**

## Week 2 Daily Standup Template

**Monday:**
- [ ] Set up Google Vision API credentials
- [ ] Set up YouTube API key
- [ ] Stub OCR handler interface

**Tuesday:**
- [ ] Implement OCR handler with Google Vision
- [ ] Write OCR integration tests

**Wednesday:**
- [ ] Implement YouTube handler
- [ ] Write YouTube integration tests

**Thursday:**
- [ ] Build orchestrator
- [ ] Add worker job processing

**Friday:**
- [ ] End-to-end testing
- [ ] Verify extracted_text table populated
- [ ] Prepare for Week 3 (Extension endpoint)

## Links & References

- Google Cloud Vision: https://cloud.google.com/vision/docs/ocr
- YouTube Transcripts: https://github.com/jdelesus/youtube-transcript-api
- Goose Migrations: https://github.com/pressly/goose
- pgx Connection Pool: https://github.com/jackc/pgx

## Week 2 â†’ Week 3 Dependency

Week 3 (Extension endpoint) needs:
- `extracted_text` table populated with real data
- Media handler working end-to-end
- Ability to search extracted text via hybrid search

Week 2 blocks Week 3 until media data is available!

---

**Status: READY FOR WEEK 2 KICKOFF** ðŸš€

Next: Monday morning, start implementing OCR handler.
